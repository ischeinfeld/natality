---
title: 'US Natality Data: Causal Inference Case Study'
output:
  html_document:
    df_print: paged
---
  
```{r echo=TRUE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE, comment=NA)

library(ggplot2)   # plot
#library(devtools)  # install from GitHub 
library(dplyr)     # tables
library(glmnet)    # lasso
library(grf)       # random forests
library(rpart)
library(sandwich)  # for robust CIs
library(tidyverse)
library(plot3D)
library(psych)
#library(causalTree)
library(estimatr)
library(ade4)  
library(viridis)
library(gridExtra)
library(janitor)

rm(list = ls())

source("utils.R")
```

# Subset and preprocess data

```{r}
year <- 2002
```

To begin with we sample 10,000 birth records uniformly at random and preprocess
their columns types from the raw CSV to encode each variable as an integer or 
an ordered or unordered factor. All values coded as missing or undetermined
are considered NA.

```{r}
subset <- FALSE
subset_size <- as.integer(1e5)
subset_fname <- paste0("../data/subset_rds/natl", year, ".rds")

if (subset) {
  raw_fname <- paste0("../data/raw_csv/natl", year, ".csv")
  natl_raw <- read_csv(raw_fname,
                   col_types = cols(.default = col_character())) %>%
    sample_n(subset_size)
  
  write_rds(natl_raw, subset_fname, compress = "gz")
}

natl_raw <- read_rds(subset_fname)
```

```{r}
preprocess <- TRUE

preprocessed_fname <- paste0("../data/preprocessed_rds/natl", year, ".rds")

if (preprocess) {
  # load preprocess_natl for this year
  source(paste0("preprocess/preprocess_natl", year, ".R"))
  
  subset_fname <- paste0("../data/subset_rds/natl", year, ".rds")
  natl <- read_rds(subset_fname) %>%
    preprocess_natl()
  
  write_rds(natl, preprocessed_fname, compress = "gz")
}

natl <- read_rds(preprocessed_fname)
```

# Prepare Data

As a sanity check for our preprocessing and to start exploring the data, we
tabulate some quick summary information.

```{r}
natl %>%
  summarise(across(.fns = function (x) sum(is.na(x)) / length(x))) %>%
  pivot_longer(cols = everything()) %>%
  arrange(desc(value)) %>%
  filter(value > 0.1)
```

The top 4 missing attributes are mplbir (mother's place of birth), fmaps (five 
minute apgar score), cntocpop (population size of county of occurrence), and
wtgain (weight gain).

Next we define our analysis in terms of covariate, treatment, and outcome
variable names.

```{r}
# variables (with most specific coding) available for analysis
natl_names <- list(
  general = c("restatus",  # residence status
              "pldel",     # place or facility of birth
              "birattnd",  # attendant at birth
              "stnatexp",  # state + NYC
              "citrspop",  # population size of city of residence 
              "metrores",  # non-metro county of residence
              "cntrspop"), # population size of county of residence
  mother = c("dmage",      # age
             "ormoth",     # Hispanic origin
             "mrace",      # race
             "dmeduc",     # education
             "dmar",       # marriage status
             "mplbir",     # place of birth
             "adequacy",   # adequacy of care
             "nlbnl",      # number of live births still living
             "nlbnd",      # "                     now dead
             "noterm",     # number of other terminations
             "dlivord",    # nlbnl + nlbnd + 1
             "monpre",     # months of prenatal care (modified coding)
             "nprevis"),   # number of prenatal visits
  father = c("dfage",      # age
             "orfath",     # Hispanic origin
             "frace"),     # race
  child = c("dgestat",     # gestation in weeks
             "csex",       # sex
             "dbirwt",     # birth weight in grams
             "dplural",    # plurality
             "fmaps",      # five minute apgar
             "delmeth5"),  # method of delivery
  med_risk = c("anemia", "cardiac", "lung", "diabetes", "herpes", "hydra", "hemo",
               "chyper", "phyper", "eclamp", "incervix", "pre4000", "preterm",
               "renal", "rh", "uterine", "othermr"),
  oth_risk = c("tobacco",  # tobacco use
               "cigar",    # avg. number of cigarettes / day
               "alcohol",  # alcohol use
               "drink",    # avg. number of drinks / week
               "wtgain"),  # weight gain
  obstetrc = c("amnio", "monitor", "induct", "stimula", "tocol", "ultras", "otherob"),
  lab_comp = c("febrile", "meconium", "rupture", "abruptio", "preplace", "excebld",
               "seizure", "precip", "prolong", "dysfunc", "breech", "cephalo",
               "cord", "anesthe", "distress", "otherlb"),
  newborn = c("nanemia", "injury", "alcosyn", "hyaline", "meconsyn", "venl30",
              "ven30m", "nseiz", "otherab"),
  congntl = c("anen", "spina", "hydro", "microce", "nervous", "heart", "circul",
              "rectal", "tracheo", "omphalo", "gastro", "genital", "renalage", 
              "urogen", "cleftlp", "adactyly", "clubfoot", "hernia", "musculo"))
```

Now we determine which subsets of variables we would like to consider as
potential treatments, covariates, and outcomes.

```{r}
# select data
Xnames <- with(natl_names, c(general, mother))
Ynames <- with(natl_names, c(newborn, congntl))
Wnames <- with(natl_names, oth_risk)

var_names <- unique(c(Xnames, Ynames, Wnames))
```

Some of our models require factors to be expanded into binary attributes.

```{r}
# Expand factor variables.
Xdata_num <- natl %>% select(all_of(Xnames)) %>% select_if(is.numeric)
Ydata_num <- natl %>% select(all_of(Ynames)) %>% select_if(is.numeric)
Wdata_num <- natl %>% select(all_of(Wnames)) %>% select_if(is.numeric)

Xdata_fct <- natl %>% select(all_of(Xnames)) %>% select_if(is.factor)
Ydata_fct <- natl %>% select(all_of(Ynames)) %>% select_if(is.factor)
Wdata_fct <- natl %>% select(all_of(Wnames)) %>% select_if(is.factor)

# expand factors
Xdata_fct_expanded <- 
  model.matrix(~., model.frame(~., Xdata_fct, na.action=na.pass))[,-1] %>% 
  as_tibble()

Ydata_fct_expanded <- 
  model.matrix(~., model.frame(~., Ydata_fct, na.action=na.pass))[,-1] %>% 
  as_tibble()

Wdata_fct_expanded <- 
  model.matrix(~., model.frame(~., Wdata_fct, na.action=na.pass))[,-1] %>% 
  as_tibble()
```

# Analyses

## Ignore missing values

First we prepare our data.

```{r}
Y <- "alcosyn"
W <- "alcohol"

Y_expanded <- "alcosynyes"
W_expanded <- "alcoholyes"

X <- c(names(Xdata_num), names(Xdata_fct))
X_expanded <- c(names(Xdata_num), names(Xdata_fct_expanded))

data <- bind_cols(Ydata_num, Ydata_fct, 
                  Wdata_num, Wdata_fct, 
                  Xdata_num, Xdata_fct) %>%
  select(all_of(c(Y, W, X))) %>%
  rename(Y = matches(Y), W = matches(W))

data_expanded <- bind_cols(
    Ydata_num, Ydata_fct_expanded, 
    Wdata_num, Wdata_fct_expanded, 
    Xdata_num, Xdata_fct_expanded
  ) %>%
  select(all_of(c(Y_expanded, W_expanded, X_expanded))) %>%
  rename(Y = matches(Y_expanded), W = matches(W_expanded))

data <- data %>%
  drop_na()

data_expanded <- data_expanded %>%
  drop_na() %>%
  remove_constant(quiet = FALSE)

X_expanded <- intersect(X_expanded, names(data_expanded))

print(paste(nrow(data) / subset_size, "of data doesn't contain NAs"))
```

### ATE Estimation

Estimating the propensity score using logistic regression.

```{r results='hide'}
Xmod = as.matrix(data_expanded[,X_expanded])
Ymod = data_expanded$Y
Wmod = data_expanded$W

# Computing the propensity score by logistic regression of W on X.
p_logistic.fit <- cv.glmnet(Xmod, Wmod, family = "binomial", relax=FALSE, trace=FALSE)
p_logistic <- predict(p_logistic.fit, newx = Xmod, type = "response")
```

We can examine the resulting coefficients (note variables are unnormalized and
this is not a measure of variable importance).

```{r}
coefs <- coef(p_logistic.fit)
perm <- order(abs(as.vector(coefs)), decreasing = TRUE)
vars <- rownames(coefs)[perm]
coefs <- coefs[perm]

tibble(vars = vars, coefs = coefs) %>%
  head(10)
```

```{r}
plot(p_logistic.fit)
```

```{r message=FALSE}
cal_plot(Wmod, p_logistic, "Propensity Score Calibration", bins = 10, lim = c(0,1))
```

Estimating the ATE using multiple methods. First, for comparison, the raw difference
in means estimator:
  
```{r}
difference_in_means <- function(dataset, Yvar, Wvar) {
  # Filter treatment / control observations, pulls outcome variable as a vector
  y1 <- dataset %>% dplyr::filter(get(Wvar) == 1) %>% dplyr::pull(get(Yvar))
  y0 <- dataset %>% dplyr::filter(get(Wvar) == 0) %>% dplyr::pull(get(Yvar))
  
  n1 <- sum(dataset[,Wvar])     # Number of obs in treatment
  n0 <- sum(1 - dataset[,Wvar]) # Number of obs in control
  
  # Difference in means is ATE
  tauhat <- mean(y1) - mean(y0)
  
  # 95% Confidence intervals
  se_hat <- sqrt( var(y0)/(n0-1) + var(y1)/(n1-1) )
  lower_ci <- tauhat - 1.96 * se_hat
  upper_ci <- tauhat + 1.96 * se_hat
  
  return(c(ATE = tauhat, lower_ci = lower_ci, upper_ci = upper_ci))
}

tauhat_difference_in_means <- difference_in_means(data_expanded, "Y", "W")

tauhat_difference_in_means
```

```{r}
ate_condmean_ols <- function(dataset, Yvar, Wvar) {
  df_mod_centered <- data.frame(scale(dataset, center = TRUE, scale = FALSE))
  
  lm.interact <- lm(as.formula(paste(Yvar, "~ . * ", Wvar)),
                   data = df_mod_centered)
  tau.hat <- as.numeric(coef(lm.interact)[Wvar])
  se.hat <- as.numeric(sqrt(vcovHC(lm.interact)[Wvar, Wvar]))
  
  c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat)
}

tauhat_ols <- ate_condmean_ols(data_expanded, "Y", "W")
print(tauhat_ols)
```

```{r}
ipw <- function(dataset, Yvar, Wvar, p) {
  W <- dataset[[Wvar]]
  Y <- dataset[[Yvar]]
  G <- ((W - p) * Y) / (p * (1 - p))
  tau.hat <- mean(G)
  se.hat <- sqrt(var(G) / (length(G) - 1))
  c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat)
}

tauhat_logistic_ipw <- ipw(data_expanded, "Y", "W", p_logistic)
print(tauhat_logistic_ipw)
```

```{r}
prop_score_ols <- function(dataset, Yvar, Wvar, p) {
  W <- dataset[[Wvar]]
  Y <- dataset[[Yvar]]
  # Computing weights
  weights <- (W / p) + ((1 - W) / (1 - p))
  # OLS
  lm.fit <- lm(Y ~ W, data = dataset, weights = weights)
  tau.hat = as.numeric(coef(lm.fit)["W"])
  se.hat = as.numeric(sqrt(vcovHC(lm.fit)["W", "W"]))
  c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat)
}

tauhat_pscore_ols <- prop_score_ols(data_expanded, "Y", "W", p_logistic)
print(tauhat_pscore_ols)
```

```{r}
aipw_ols <- function(dataset, Yvar, Wvar, p) {
  ols.fit <-  lm(as.formula(paste(Yvar, "~ . * ", Wvar)), data = dataset)
  
  dataset.treatall <- dataset
  dataset.treatall <- dataset.treatall %>%
    mutate(!!Wvar := 1)
  treated_pred = predict(ols.fit, dataset.treatall)
  
  dataset.treatnone = dataset
  dataset.treatall <- dataset.treatnone %>%
    mutate(!!Wvar := 0)
  control_pred = predict(ols.fit, dataset.treatnone)
  
  actual_pred = predict(ols.fit, dataset)
  
  G <- treated_pred - control_pred +
    ((dataset[[Wvar]] - p) * (dataset[[Yvar]] - actual_pred)) / (p * (1 - p))
  tau.hat <- mean(G)
  se.hat <- sqrt(var(G) / (length(G) - 1))
  c(ATE=tau.hat, lower_ci = tau.hat - 1.96 * se.hat, upper_ci = tau.hat + 1.96 * se.hat)
}

tauhat_lin_logistic_aipw <- aipw_ols(data_expanded, "Y", "W", p_logistic)
print(tauhat_lin_logistic_aipw)
```


